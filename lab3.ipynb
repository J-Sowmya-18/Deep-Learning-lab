{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuRRbnlUbJKzUNrRYQtILq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J-Sowmya-18/Deep-Learning-lab/blob/main/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1mzFrwpk7kt",
        "outputId": "1c10b059-520a-4045-bda8-318712712571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar value: 5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Scalar_ex\n",
        "scalar = np.array(5)\n",
        "print(\"Scalar value:\", scalar)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector example\n",
        "vector = np.array([1, 2, 3])\n",
        "print(\"Vector values:\", vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhVB0cdXlHB0",
        "outputId": "f9076c20-4fce-4a42-abb3-b83e74a15572"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector values: [1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#scalar_ex\n",
        "scalar=np.array(5)\n",
        "print(\"Scalar value:\",scalar)\n",
        "#vector ex\n",
        "vector=np.array([1,2,3])\n",
        "print(\"Vector values:\",vector)\n",
        "#2d tensor ex\n",
        "matrix=np.array([[1,2,3],[4,5,6]])\n",
        "print(\"2d tensor (matrix):\\n\",matrix)\n",
        "#3d tensor_ex\n",
        "tensor_3d=np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
        "print(\"3d tensor:\\n\",tensor_3d)\n",
        "#4d tensor_es\n",
        "tensor_4d=np.random.rand(2,3,4,5)\n",
        "print(\"Shape of 4d tensor:\",tensor_4d.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7-PO4mOlhRP",
        "outputId": "76361a76-fc93-4b4e-b9ad-bb22ba5ebdf7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar value: 5\n",
            "Vector values: [1 2 3]\n",
            "2d tensor (matrix):\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "3d tensor:\n",
            " [[[ 1  2  3]\n",
            "  [ 4  5  6]]\n",
            "\n",
            " [[ 7  8  9]\n",
            "  [10 11 12]]]\n",
            "Shape of 4d tensor: (2, 3, 4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TudwKwQxl0LW",
        "outputId": "f2446f39-9637-44a8-d661-2a10443e4958"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 8425.9854 - val_loss: 4926.4219\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 2153.0522 - val_loss: 388.7645\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 187.5041 - val_loss: 100.2128\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 71.6242 - val_loss: 43.8374\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 32.6530 - val_loss: 23.0584\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 21.6979\n",
            "Test Loss: 21.697925567626953\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "Predicted Sum: 65.37844848632812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden\n",
        "model.add(Dense(1))  # Output\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.3)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Ex_input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFSz1NmomJ3P",
        "outputId": "5cceb568-ad19-4c56-8657-6900566ba895"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "77/77 [==============================] - 2s 9ms/step - loss: 9505.7334 - val_loss: 6443.7144\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 4164.2866 - val_loss: 2104.0481\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1188.1875 - val_loss: 566.2463\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 384.7094 - val_loss: 223.2211\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 157.7527 - val_loss: 91.6822\n",
            "94/94 [==============================] - 0s 1ms/step - loss: 100.8571\n",
            "Test Loss: 100.85706329345703\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Predicted Sum: 64.7323989868164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden\n",
        "model.add(Dense(1))  # Output\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.3)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0B7a0y9md4w",
        "outputId": "e7b52178-bf70-4173-c6c7-861ed43869ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "77/77 [==============================] - 2s 8ms/step - loss: 8243.5273 - val_loss: 5634.8667\n",
            "Epoch 2/10\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 2979.8909 - val_loss: 781.8811\n",
            "Epoch 3/10\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 222.1254 - val_loss: 18.9047\n",
            "Epoch 4/10\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 11.1421 - val_loss: 7.1572\n",
            "Epoch 5/10\n",
            "77/77 [==============================] - 1s 10ms/step - loss: 5.3616 - val_loss: 3.7712\n",
            "Epoch 6/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 2.9881 - val_loss: 2.2946\n",
            "Epoch 7/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.9473 - val_loss: 1.6329\n",
            "Epoch 8/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.4671 - val_loss: 1.3107\n",
            "Epoch 9/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.2114 - val_loss: 1.1200\n",
            "Epoch 10/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.0387 - val_loss: 0.9845\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 1.0074\n",
            "Test Loss: 1.0073515176773071\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "Predicted Sum: 68.06450653076172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=7, batch_size=64, validation_split=0.3)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0il7VgDlmsbM",
        "outputId": "51b7768b-5541-496d-b458-3df76772b252"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "77/77 [==============================] - 1s 5ms/step - loss: 1463.6589 - val_loss: 341.5959\n",
            "Epoch 2/7\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 85.3803 - val_loss: 12.2491\n",
            "Epoch 3/7\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 7.7799 - val_loss: 5.5074\n",
            "Epoch 4/7\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 3.8294 - val_loss: 2.9510\n",
            "Epoch 5/7\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 2.1626 - val_loss: 1.6712\n",
            "Epoch 6/7\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.2621 - val_loss: 0.9790\n",
            "Epoch 7/7\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7469 - val_loss: 0.5702\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 0.5931\n",
            "Test Loss: 0.5931494235992432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e96b6636830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "Predicted Sum: 68.25399780273438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.3)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[10, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWz_rJAjm21H",
        "outputId": "a1f7c2c4-3815-46ba-d635-b927478ee6c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "77/77 [==============================] - 1s 4ms/step - loss: 5865.6875 - val_loss: 3780.1428\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1866.7888 - val_loss: 451.6869\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 131.6298 - val_loss: 38.3747\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 26.1040 - val_loss: 20.4630\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 16.6133 - val_loss: 14.5144\n",
            "94/94 [==============================] - 0s 1ms/step - loss: 13.8619\n",
            "Test Loss: 13.861869812011719\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Predicted Sum: 56.651649475097656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden\n",
        "model.add(Dense(1))  # Output\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=8, batch_size=64, validation_split=0.3)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[20, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0gcPse1nM6i",
        "outputId": "ab2160c4-f580-46b1-84ba-dfa0869ac066"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "77/77 [==============================] - 1s 5ms/step - loss: 13875.7275 - val_loss: 12779.6035\n",
            "Epoch 2/8\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 11626.8438 - val_loss: 9544.6709\n",
            "Epoch 3/8\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 6322.1562 - val_loss: 2798.4507\n",
            "Epoch 4/8\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 929.4500 - val_loss: 26.1064\n",
            "Epoch 5/8\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 19.1112 - val_loss: 13.9600\n",
            "Epoch 6/8\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 12.5308 - val_loss: 10.7529\n",
            "Epoch 7/8\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 9.9115 - val_loss: 8.6942\n",
            "Epoch 8/8\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 8.0673 - val_loss: 7.1985\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 7.8361\n",
            "Test Loss: 7.8360514640808105\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "Predicted Sum: 65.97876739501953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.3)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[10, 15]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgy0dc27oMml",
        "outputId": "29245673-a481-4931-8deb-46bed319c430"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "77/77 [==============================] - 1s 5ms/step - loss: 6650.6953 - val_loss: 4261.3115\n",
            "Epoch 2/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 2373.9077 - val_loss: 1011.4827\n",
            "Epoch 3/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 551.7926 - val_loss: 357.0482\n",
            "Epoch 4/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 281.2703 - val_loss: 227.9698\n",
            "Epoch 5/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 154.8137 - val_loss: 93.5593\n",
            "Epoch 6/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 54.4334 - val_loss: 31.3629\n",
            "Epoch 7/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 20.4925 - val_loss: 13.8598\n",
            "Epoch 8/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 9.8823 - val_loss: 7.1311\n",
            "Epoch 9/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 5.3319 - val_loss: 4.1205\n",
            "Epoch 10/10\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 3.0921 - val_loss: 2.4236\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 2.3692\n",
            "Test Loss: 2.369194984436035\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Predicted Sum: 25.645305633544922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden layer\n",
        "model.add(Dense(1))  # Output layer\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=12, batch_size=32, validation_split=0.3)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[23, 45]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRu5VNeQoaoF",
        "outputId": "8bd9d9f8-4014-4262-bf79-dd116fc69003"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 3086.4956 - val_loss: 1242.3594\n",
            "Epoch 2/12\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 658.6569 - val_loss: 229.9999\n",
            "Epoch 3/12\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 97.1566 - val_loss: 25.1538\n",
            "Epoch 4/12\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 14.9750 - val_loss: 8.3647\n",
            "Epoch 5/12\n",
            "154/154 [==============================] - 1s 3ms/step - loss: 7.4616 - val_loss: 5.8615\n",
            "Epoch 6/12\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 5.7191 - val_loss: 5.1582\n",
            "Epoch 7/12\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 4.9847 - val_loss: 4.7000\n",
            "Epoch 8/12\n",
            "154/154 [==============================] - 0s 3ms/step - loss: 4.4786 - val_loss: 4.2281\n",
            "Epoch 9/12\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 4.0203 - val_loss: 3.8404\n",
            "Epoch 10/12\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 3.6132 - val_loss: 3.4474\n",
            "Epoch 11/12\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 3.2344 - val_loss: 3.0656\n",
            "Epoch 12/12\n",
            "154/154 [==============================] - 1s 5ms/step - loss: 2.9168 - val_loss: 2.7341\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 2.5857\n",
            "Test Loss: 2.5856876373291016\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "Predicted Sum: 68.51702880859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Generate Training Data\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# Step 2: Define the Model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))  # Input layer with 2 inputs\n",
        "model.add(Dense(5, activation='relu'))  # Hidden\n",
        "model.add(Dense(1))  # Output\n",
        "# Step 3: Compile the Model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=0.2)\n",
        "# Step 5: Evaluate the Model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "# Make a prediction\n",
        "sample_input = np.array([[20, 40]])  # Example input\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-gMt3pxopHl",
        "outputId": "31f31d1c-e7ea-4151-c89c-fcaa97a44fa3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "88/88 [==============================] - 1s 6ms/step - loss: 10216.3604 - val_loss: 8362.6016\n",
            "Epoch 2/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 4949.2905 - val_loss: 1224.7729\n",
            "Epoch 3/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 366.5815 - val_loss: 120.6791\n",
            "Epoch 4/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 65.6812 - val_loss: 36.5249\n",
            "Epoch 5/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 24.6211 - val_loss: 19.2012\n",
            "Epoch 6/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 15.8653 - val_loss: 14.3428\n",
            "Epoch 7/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 12.5394 - val_loss: 11.8500\n",
            "Epoch 8/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 10.4820 - val_loss: 10.0984\n",
            "Epoch 9/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 8.9929 - val_loss: 8.8152\n",
            "Epoch 10/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 7.8648 - val_loss: 7.8428\n",
            "Epoch 11/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 6.9670 - val_loss: 7.0377\n",
            "Epoch 12/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 6.2199 - val_loss: 6.3582\n",
            "Epoch 13/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 5.5909 - val_loss: 5.7759\n",
            "Epoch 14/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 5.0602 - val_loss: 5.2732\n",
            "Epoch 15/15\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 4.5913 - val_loss: 4.8259\n",
            "94/94 [==============================] - 0s 1ms/step - loss: 4.3668\n",
            "Test Loss: 4.366819381713867\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Predicted Sum: 59.47346496582031\n"
          ]
        }
      ]
    }
  ]
}